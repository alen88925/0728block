{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\BoJia\\Anaconda3\\envs\\cu118pt\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\BoJia\\Anaconda3\\envs\\cu118pt\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape: torch.Size([1, 64, 112, 256])\n",
      "x2 shape: torch.Size([1, 256, 56, 128])\n",
      "x3 shape: torch.Size([1, 512, 28, 64])\n",
      "x4 shape: torch.Size([1, 1024, 14, 32])\n",
      "x5 shape: torch.Size([1, 2048, 7, 16])\n",
      "Bridge x5 shape: torch.Size([1, 2048, 7, 16])\n",
      "Upsampled x1 shape: torch.Size([1, 1024, 14, 32]), x2 shape: torch.Size([1, 1024, 14, 32])\n",
      "Upsampled x1 shape: torch.Size([1, 512, 28, 64]), x2 shape: torch.Size([1, 512, 28, 64])\n",
      "Upsampled x1 shape: torch.Size([1, 256, 56, 128]), x2 shape: torch.Size([1, 256, 56, 128])\n",
      "Upsampled x1 shape: torch.Size([1, 64, 112, 256]), x2 shape: torch.Size([1, 64, 112, 256])\n",
      "torch.Size([1, 1, 112, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=8):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels, in_channels // reduction_ratio, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // reduction_ratio, in_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn = self.channel_attention(x)\n",
    "        return x * attn\n",
    "\n",
    "class GroupConv(nn.Module):\n",
    "    \"\"\"Grouped convolution with different dilation rates and attention\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, groups):\n",
    "        super(GroupConv, self).__init__()\n",
    "        assert in_channels % groups == 0, \"in_channels must be divisible by groups\"\n",
    "        assert out_channels % groups == 0, \"out_channels must be divisible by groups\"\n",
    "        self.groups = groups\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels // groups, out_channels // groups, kernel_size=3, padding=d, dilation=d)\n",
    "            for d in range(1, groups + 1)\n",
    "        ])\n",
    "        self.attentions = nn.ModuleList([\n",
    "            AttentionBlock(out_channels // groups)\n",
    "            for _ in range(groups)\n",
    "        ])\n",
    "        self.integrate_conv = nn.Conv2d(out_channels, out_channels, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        split_x = torch.split(x, x.size(1) // self.groups, dim=1)\n",
    "        conv_x = [conv(split) for conv, split in zip(self.convs, split_x)]\n",
    "        attn_x = [attn(conv_out) for attn, conv_out in zip(self.attentions, conv_x)]\n",
    "        x = torch.cat(attn_x, dim=1)\n",
    "        x = self.integrate_conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Up, self).__init__()\n",
    "        if in_channels == 256:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 4, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels // 2, out_channels)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        print(f'Upsampled x1 shape: {x1.shape}, x2 shape: {x2.shape}')\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        x1 = nn.functional.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class CustomResNet50UNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(CustomResNet50UNet, self).__init__()\n",
    "        self.resnet50 = models.resnet50(pretrained=True)\n",
    "        self.resnet50.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        \n",
    "        # 保留 ResNet50 的所有層，直到展平層之前\n",
    "        self.encoder = nn.Sequential(*list(self.resnet50.children())[:-2])\n",
    "\n",
    "        # 分组卷积层，使用四个不同的膨胀率\n",
    "        self.group_conv = GroupConv(2048, 2048, groups=4)\n",
    "\n",
    "        self.up1 = Up(2048, 1024)\n",
    "        self.up2 = Up(1024, 512)\n",
    "        self.up3 = Up(512, 256)\n",
    "        self.up4 = Up(256, 64)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(64, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.resnet50.conv1(x)\n",
    "        x1 = self.resnet50.bn1(x1)\n",
    "        x1 = self.resnet50.relu(x1)\n",
    "        x2 = self.resnet50.maxpool(x1)\n",
    "        print(f'x1 shape: {x1.shape}')\n",
    "        \n",
    "        x2 = self.resnet50.layer1(x2)\n",
    "        print(f'x2 shape: {x2.shape}')\n",
    "        x3 = self.resnet50.layer2(x2)\n",
    "        print(f'x3 shape: {x3.shape}')\n",
    "        x4 = self.resnet50.layer3(x3)\n",
    "        print(f'x4 shape: {x4.shape}')\n",
    "        x5 = self.resnet50.layer4(x4)\n",
    "        print(f'x5 shape: {x5.shape}')\n",
    "        \n",
    "        # Bridge\n",
    "        x5 = self.group_conv(x5)\n",
    "        print(f'Bridge x5 shape: {x5.shape}')\n",
    "        \n",
    "        # Decoder\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        \n",
    "        x = self.final_conv(x)\n",
    "        return x\n",
    "\n",
    "# 測試模型\n",
    "model = CustomResNet50UNet(n_classes=1)\n",
    "model = model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "input_tensor = torch.randn(1, 3, 224, 512).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "output = model(input_tensor)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 224, 512])\n"
     ]
    }
   ],
   "source": [
    "#seg_model.py\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=8):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels, in_channels // reduction_ratio, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // reduction_ratio, in_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn = self.channel_attention(x)\n",
    "        return x * attn\n",
    "\n",
    "class GroupConv(nn.Module):\n",
    "    \"\"\"Grouped convolution with different dilation rates and attention\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, groups):\n",
    "        super(GroupConv, self).__init__()\n",
    "        assert in_channels % groups == 0, \"in_channels must be divisible by groups\"\n",
    "        assert out_channels % groups == 0, \"out_channels must be divisible by groups\"\n",
    "        self.groups = groups\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels // groups, out_channels // groups, kernel_size=3, padding=d, dilation=d)\n",
    "            for d in range(1, groups + 1)\n",
    "        ])\n",
    "        self.attentions = nn.ModuleList([\n",
    "            AttentionBlock(out_channels // groups)\n",
    "            for _ in range(groups)\n",
    "        ])\n",
    "        self.integrate_conv = nn.Conv2d(out_channels, out_channels, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        split_x = torch.split(x, x.size(1) // self.groups, dim=1)\n",
    "        conv_x = [conv(split) for conv, split in zip(self.convs, split_x)]\n",
    "        attn_x = [attn(conv_out) for attn, conv_out in zip(self.attentions, conv_x)]\n",
    "        x = torch.cat(attn_x, dim=1)\n",
    "        x = self.integrate_conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResUnet(nn.Module):\n",
    "    def __init__(self, num_classes=1, pretrained=True):\n",
    "        super(ResUnet, self).__init__()\n",
    "        self.base_model = models.resnet50(pretrained=pretrained)\n",
    "        self.base_layers = list(self.base_model.children())\n",
    "\n",
    "        self.layer0 = nn.Sequential(*self.base_layers[:3])  # 64\n",
    "        self.layer1 = nn.Sequential(*self.base_layers[3:5])  # 256\n",
    "        self.layer2 = self.base_layers[5]  # 512\n",
    "        self.layer3 = self.base_layers[6]  # ｛\n",
    "        self.layer4 = self.base_layers[7]  # 2048\n",
    "\n",
    "        # 分组卷积层，使用四个不同的膨胀率\n",
    "        self.group_conv = GroupConv(2048, 2048, groups=4)\n",
    "\n",
    "        self.upsample4 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.upsample3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.conv_up4 = nn.Conv2d(2048 + 1024, 1024, kernel_size=3, padding=1)\n",
    "        self.conv_up3 = nn.Conv2d(1024 + 512, 512, kernel_size=3, padding=1)\n",
    "        self.conv_up2 = nn.Conv2d(512 + 256, 256, kernel_size=3, padding=1)\n",
    "        self.conv_up1 = nn.Conv2d(256 + 64, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        layer0_out = self.layer0(x)\n",
    "        layer1_out = self.layer1(layer0_out)\n",
    "        layer2_out = self.layer2(layer1_out)\n",
    "        layer3_out = self.layer3(layer2_out)\n",
    "        layer4_out = self.layer4(layer3_out)\n",
    "\n",
    "        layer4_out = self.group_conv(layer4_out)\n",
    "\n",
    "        x = self.upsample4(layer4_out)\n",
    "        x = torch.cat([x, layer3_out], dim=1)\n",
    "        x = self.relu(self.conv_up4(x))\n",
    "\n",
    "        x = self.upsample3(x)\n",
    "        x = torch.cat([x, layer2_out], dim=1)\n",
    "        x = self.relu(self.conv_up3(x))\n",
    "\n",
    "        x = self.upsample2(x)\n",
    "        x = torch.cat([x, layer1_out], dim=1)\n",
    "        x = self.relu(self.conv_up2(x))\n",
    "\n",
    "        x = self.upsample1(x)\n",
    "        x = torch.cat([x, layer0_out], dim=1)\n",
    "        x = self.relu(self.conv_up1(x))\n",
    "        x = self.upsample1(x)\n",
    "        x = self.conv_last(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = ResUnet(num_classes=1, pretrained=False)\n",
    "model = model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "input_tensor = torch.randn(1, 3, 224, 512).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "output = model(input_tensor)\n",
    "print(output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
